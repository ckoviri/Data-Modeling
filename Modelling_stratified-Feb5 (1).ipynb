{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset into a dataframe named FINALDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "FINALDATA=pd.read_excel(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\Final_labeled_File.xlsx\",sheet_name = \"Sheet2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether any null values exists in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".of Mails                         0\n",
       "Term                              0\n",
       "LTL+Other Plan                    0\n",
       "CERT_CL                           0\n",
       "MEM_CODE                          0\n",
       "I_CLASS                           0\n",
       "I_SEX                             0\n",
       "MODE                              0\n",
       "ISSU_STATE                        0\n",
       "RISK_CLASS                        0\n",
       "md_do                             0\n",
       "visa_code                         0\n",
       "Current Member status             0\n",
       "prim_spec                         0\n",
       "prim_top                          0\n",
       "prim_pe                           0\n",
       "mpa_code                          0\n",
       "ANNZD_PREM                        0\n",
       "I_CURR_AGE                        0\n",
       "I_AGE_ISSU                        0\n",
       "Duration                          0\n",
       "yrs_pract                         0\n",
       "Total_years_of_membership         0\n",
       "Continuous_years_of_membership    0\n",
       "EFF_D                             0\n",
       "CMP_D                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINALDATA.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".of Mails                         float64\n",
       "Term                                int64\n",
       "LTL+Other Plan                      int64\n",
       "CERT_CL                             int64\n",
       "MEM_CODE                            int64\n",
       "I_CLASS                             int64\n",
       "I_SEX                               int64\n",
       "MODE                                int64\n",
       "ISSU_STATE                          int64\n",
       "RISK_CLASS                          int64\n",
       "md_do                               int64\n",
       "visa_code                           int64\n",
       "Current Member status               int64\n",
       "prim_spec                           int64\n",
       "prim_top                            int64\n",
       "prim_pe                             int64\n",
       "mpa_code                            int64\n",
       "ANNZD_PREM                          int64\n",
       "I_CURR_AGE                          int64\n",
       "I_AGE_ISSU                          int64\n",
       "Duration                          float64\n",
       "yrs_pract                         float64\n",
       "Total_years_of_membership         float64\n",
       "Continuous_years_of_membership    float64\n",
       "EFF_D                             float64\n",
       "CMP_D                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINALDATA.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the dummy labelled categorical variables dtype=\"Category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINALDATA[\"Term\"] = FINALDATA[\"Term\"].astype(\"category\")\n",
    "FINALDATA[\"LTL+Other Plan\"] = FINALDATA[\"LTL+Other Plan\"].astype(\"category\")\n",
    "FINALDATA[\"CERT_CL\"] = FINALDATA[\"CERT_CL\"].astype(\"category\")\n",
    "FINALDATA[\"MEM_CODE\"] = FINALDATA[\"MEM_CODE\"].astype(\"category\")\n",
    "FINALDATA[\"I_CLASS\"] = FINALDATA[\"I_CLASS\"].astype(\"category\")\n",
    "FINALDATA[\"I_SEX\"] = FINALDATA[\"I_SEX\"].astype(\"category\")\n",
    "FINALDATA[\"MODE\"] = FINALDATA[\"MODE\"].astype(\"category\")\n",
    "FINALDATA[\"ISSU_STATE\"] = FINALDATA[\"ISSU_STATE\"].astype(\"category\")\n",
    "FINALDATA[\"md_do\"] = FINALDATA[\"md_do\"].astype(\"category\")\n",
    "FINALDATA[\"visa_code\"] = FINALDATA[\"visa_code\"].astype(\"category\")\n",
    "FINALDATA[\"Current Member status\"] = FINALDATA[\"Current Member status\"].astype(\"category\")\n",
    "FINALDATA[\"prim_spec\"] = FINALDATA[\"prim_spec\"].astype(\"category\")\n",
    "FINALDATA[\"prim_top\"] = FINALDATA[\"prim_top\"].astype(\"category\")\n",
    "FINALDATA[\"prim_pe\"] = FINALDATA[\"prim_pe\"].astype(\"category\")\n",
    "FINALDATA[\"mpa_code\"] = FINALDATA[\"mpa_code\"].astype(\"category\")\n",
    "FINALDATA[\"ANNZD_PREM\"] = FINALDATA[\"ANNZD_PREM\"].astype(\"category\")\n",
    "FINALDATA[\"RISK_CLASS\"] = FINALDATA[\"RISK_CLASS\"].astype(\"category\")\n",
    "FINALDATA[\"I_CURR_AGE\"] = FINALDATA[\"I_CURR_AGE\"].astype(\"category\")\n",
    "FINALDATA[\"I_AGE_ISSU\"] = FINALDATA[\"I_AGE_ISSU\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the datatypes of FINALDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".of Mails                          float64\n",
       "Term                              category\n",
       "LTL+Other Plan                    category\n",
       "CERT_CL                           category\n",
       "MEM_CODE                          category\n",
       "I_CLASS                           category\n",
       "I_SEX                             category\n",
       "MODE                              category\n",
       "ISSU_STATE                        category\n",
       "RISK_CLASS                        category\n",
       "md_do                             category\n",
       "visa_code                         category\n",
       "Current Member status             category\n",
       "prim_spec                         category\n",
       "prim_top                          category\n",
       "prim_pe                           category\n",
       "mpa_code                          category\n",
       "ANNZD_PREM                        category\n",
       "I_CURR_AGE                        category\n",
       "I_AGE_ISSU                        category\n",
       "Duration                           float64\n",
       "yrs_pract                          float64\n",
       "Total_years_of_membership          float64\n",
       "Continuous_years_of_membership     float64\n",
       "EFF_D                              float64\n",
       "CMP_D                              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINALDATA.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [36274 12987 40751 ... 37028 29827   397] TEST: [13100 45017 15496 ... 43209 52445 15138]\n",
      "TRAIN: [24474 20606 12278 ... 22977 20177 52417] TEST: [47206 21904 50269 ... 43562 42372 16192]\n",
      "TRAIN: [36088 47126  8779 ... 23118 18860  4112] TEST: [ 3992 20438  9618 ... 24998  9608  5106]\n",
      "TRAIN: [34025 16534 16663 ... 38487 41624 32350] TEST: [10518 14103 26763 ... 29823 49849 33846]\n",
      "TRAIN: [36865   846 44325 ...  2780 16979 16387] TEST: [21937 38192 37534 ... 15513 33446 44502]\n",
      "TRAIN: [10645 27849 38693 ... 20353  3482 43698] TEST: [37888 24931 42889 ... 40480 45365 51865]\n",
      "TRAIN: [30916 22798 18015 ... 39544 18267 29143] TEST: [50085 37120 43483 ...   792 31954 45495]\n",
      "TRAIN: [38886 25526 28643 ... 28500 22703  6801] TEST: [15414  9186 25012 ...   958 25897 37689]\n",
      "TRAIN: [33269 16902 43005 ...  8558  1850  8200] TEST: [  189  9582 45146 ...  9295 32778 32985]\n",
      "TRAIN: [13129 46116 22522 ...  9685  5006 24041] TEST: [ 1326 24186 42718 ... 33222 46018 19854]\n",
      "TRAIN: [45037 45390 23653 ... 49676 13786 48005] TEST: [ 7354 36225  7094 ... 12951 35477 43793]\n",
      "TRAIN: [52176 27680 34901 ... 23553 32995  5731] TEST: [  365 26142 11094 ... 35996 17500  3817]\n",
      "TRAIN: [19546 17434 49447 ... 36132 20534 14563] TEST: [  373 15018 34874 ... 15985  7430 19748]\n",
      "TRAIN: [42877 20291 35811 ... 37089  7805  8760] TEST: [24218 18519 38683 ... 50009 45652 10802]\n",
      "TRAIN: [14850 41761  3191 ... 25559 40389 20863] TEST: [47909 31139 12313 ... 34230 35342   476]\n",
      "TRAIN: [34409  1399 13636 ... 12667 36359  1363] TEST: [23402 16869 28623 ... 49328  1608 26304]\n",
      "TRAIN: [47106 10346 31356 ... 27271 43923 19496] TEST: [49199 50418 47149 ...  5546 38706 10302]\n",
      "TRAIN: [50330 25416 31353 ... 29701 45512 30681] TEST: [44085 24763 40516 ... 48118 12291 35191]\n",
      "TRAIN: [32980 43582 51994 ...  7481 13629  4362] TEST: [27022 30553 46620 ... 18888 42069 51250]\n",
      "TRAIN: [ 1346    77 45682 ... 47471  2964 29237] TEST: [10093 37369 36479 ... 51670 16704 11902]\n",
      "TRAIN: [37745 40758 25938 ... 16244 45204 49458] TEST: [17507 10433 37590 ...  5890 35300 23627]\n",
      "TRAIN: [   33 41245 20986 ... 41700  2337 49024] TEST: [40915 51069 26385 ... 33264 50300 25740]\n",
      "TRAIN: [ 5749 33306 41121 ... 44226 29306 23435] TEST: [18544 51888 47110 ... 17081 45271 14126]\n",
      "TRAIN: [33529  6840  9574 ... 39188 25225  9941] TEST: [30563 27785 43034 ... 39777 52271 39613]\n",
      "TRAIN: [33266 13627 18553 ... 43591 46721 14151] TEST: [50344 11678 38576 ... 24323  5407 36325]\n",
      "TRAIN: [ 5742  3486 31540 ...  7471  7482 16184] TEST: [40180 51237 31453 ... 38665 20497 15226]\n",
      "TRAIN: [23772 50377 30398 ...  9215 33395 45434] TEST: [ 6376 41969  8674 ... 38394 11368 39599]\n",
      "TRAIN: [52315 43620 47749 ... 49059 41244 12622] TEST: [ 1667  1207 41645 ...  2167  1141 43930]\n",
      "TRAIN: [32449 14692 24957 ... 43039 30567 10126] TEST: [36897 23316  1837 ... 20182 43008 46721]\n",
      "TRAIN: [29544 19168 43277 ... 50042  7918 35642] TEST: [20860 24854 43729 ... 18608 50870 16899]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=30, test_size=0.4, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(FINALDATA,FINALDATA[\"CERT_CL\"]):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_strat = FINALDATA.loc[train_index]\n",
    "    test_strat = FINALDATA.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21030, 26)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the remaining data after getting the train split- into new test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21030\n",
      "21030 10515\n"
     ]
    }
   ],
   "source": [
    "val = test_strat.sample(frac =.5) \n",
    "print(len(test_strat))\n",
    "# checking if sample is 0.5 times data or not \n",
    "\n",
    "if (0.5*(len(test_strat)))== len(val): \n",
    "    print(len(test_strat), len(val))\n",
    "  \n",
    "# display \n",
    "#val.head()\n",
    "test_strat= test_strat.drop(val.index)\n",
    "#test_strat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the validation data and deriving x and y dataframes from the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val.drop(columns=\"CERT_CL\")\n",
    "val_y = val[\"CERT_CL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the validation X and Y dataframes,train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10515,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape\n",
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31545, 26)\n",
      "(10515, 26)\n"
     ]
    }
   ],
   "source": [
    "print(train_strat.shape)\n",
    "print(test_strat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Value counts of CERT_CL in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    13493\n",
      "0     9982\n",
      "1     8070\n",
      "Name: CERT_CL, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cfc1a8fc18>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(train_strat['CERT_CL'].value_counts())\n",
    "sns.countplot(train_strat['CERT_CL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_1 = 9982\n",
    "count_class_2 = 8070\n",
    "count_class_3 = 13493"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling the 3 groups in the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1 = train_strat[train_strat[\"CERT_CL\"] == 0]\n",
    "df_class_2 = train_strat[train_strat[\"CERT_CL\"]== 1]\n",
    "df_class_3 = train_strat[train_strat[\"CERT_CL\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_1*8 , replace=True)\n",
    "df_class_2_over = df_class_2.sample(count_class_2*2, replace=True)\n",
    "df_class_3_over = df_class_3.sample(count_class_3*2, replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    79856\n",
      "2    26986\n",
      "1    16140\n",
      "Name: CERT_CL, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "df_train_over = pd.concat([df_class_1_over,df_class_2_over,df_class_3_over], axis=0)\n",
    "print('Random over-sampling:')\n",
    "print(df_train_over[\"CERT_CL\"].value_counts())\n",
    "df_train_over.columns\n",
    "df_train_over[\"CERT_CL\"].value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deriving the X and Y dataframes from train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx1_strat = df_train_over.drop(columns = [\"CERT_CL\",\"Duration\"])\n",
    "trainy1_strat = df_train_over[\"CERT_CL\"]\n",
    "#trainy1_strat = trainy1_strat.astype(float)\n",
    "testx1_strat = test_strat.drop(columns = [\"CERT_CL\",\"Duration\"])\n",
    "testy1_strat = test_strat[\"CERT_CL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val.drop(columns=[\"CERT_CL\",\"Duration\"])\n",
    "val_y = val[\"CERT_CL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification with Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9531945  -0.25353255 -0.69966194]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Intercepts:\n",
      " [ 0.9531945  -0.25353255 -0.69966194] \n",
      "\n",
      "Coefficients\n",
      ": [[ 1.76052587e-01  9.29908401e-02  3.12949703e-01  9.30745186e-02\n",
      "  -4.49943723e-02 -1.31264915e-01 -7.14851989e-02 -2.30439390e-04\n",
      "   1.49419918e+00 -8.54564516e-03  8.74423459e-04 -8.77596209e-01\n",
      "  -1.28369625e-04 -1.33995934e-02  4.44403574e-03  3.20246952e-02\n",
      "  -1.25814898e-01  7.75457019e-01 -6.38703781e-01 -6.21930300e-01\n",
      "  -6.15622582e-01 -1.63396342e-02 -1.03066647e-01 -2.69634673e-01]\n",
      " [ 1.06213144e+00 -1.11477221e-01 -1.80896883e-01 -3.01610770e-02\n",
      "   6.36612300e-02 -2.31131457e-02  2.34941308e-02  1.81205690e-03\n",
      "  -2.48838512e+00 -3.58069059e-03  1.19719417e-04  4.36535634e-01\n",
      "   4.05027170e-04  9.55365398e-03 -2.79878187e-03 -2.35306286e-02\n",
      "   1.25769072e-01  4.03059477e-01 -5.40799993e-01  4.96166175e-01\n",
      "   4.38771397e-01 -2.50676193e-02 -9.30945923e-03  2.19507022e-01]\n",
      " [-1.23818403e+00  1.84863811e-02 -1.32052821e-01 -6.29134416e-02\n",
      "  -1.86668578e-02  1.54378060e-01  4.79910680e-02 -1.58161758e-03\n",
      "   9.94185943e-01  1.21263357e-02 -9.94142848e-04  4.41060575e-01\n",
      "  -2.76657784e-04  3.84593960e-03 -1.64525399e-03 -8.49406660e-03\n",
      "   4.58265418e-05 -1.17851650e+00  1.17950377e+00  1.25764125e-01\n",
      "   1.76851185e-01  4.14072535e-02  1.12376106e-01  5.01276510e-02]] \n",
      "\n",
      "Probabilities:\n",
      " [[7.29248062e-01 2.43785876e-01 2.69660620e-02]\n",
      " [3.73967772e-01 3.86347076e-02 5.87397520e-01]\n",
      " [6.01127691e-01 1.59085233e-02 3.82963785e-01]\n",
      " ...\n",
      " [8.58099753e-01 8.62997362e-02 5.56005110e-02]\n",
      " [8.15041174e-01 3.55735351e-05 1.84923252e-01]\n",
      " [1.07851837e-01 1.45306885e-01 7.46841278e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#logmodel_strat = LogisticRegression(random_state=0,C=1.0,max_iter=50,penalty='l2',tol=0.0001)\n",
    "logmodel_strat = LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_Strat=logmodel_strat.fit(trainx1_strat,trainy1_strat)\n",
    "#print(logmodel_strat.fit(trainx1_strat,trainy1_strat))\n",
    "print(logmodel_strat.intercept_)\n",
    "#y = mx \n",
    "print(logmodel_strat.fit(trainx1_strat,trainy1_strat))\n",
    "predictions = logmodel_strat.predict(trainx1_strat)\n",
    "#print(predictions)\n",
    "predictions1 = logmodel_strat.predict(testx1_strat)\n",
    "#print(predictions1)\n",
    "predictions_val = logmodel_strat.predict(val_x)\n",
    "print(\"Intercepts:\\n\",Model_Strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_Strat.coef_,\"\\n\")\n",
    "print(\"Probabilities:\\n\",Model_Strat.predict_proba(testx1_strat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[0 0 0 ... 2 1 2]\n",
      "[0 2 0 ... 0 0 2]\n",
      "Intercepts:\n",
      " [ 0.9531945  -0.25353255 -0.69966194] \n",
      "\n",
      "Coefficients\n",
      ": [[ 1.76052587e-01  9.29908401e-02  3.12949703e-01  9.30745186e-02\n",
      "  -4.49943723e-02 -1.31264915e-01 -7.14851989e-02 -2.30439390e-04\n",
      "   1.49419918e+00 -8.54564516e-03  8.74423459e-04 -8.77596209e-01\n",
      "  -1.28369625e-04 -1.33995934e-02  4.44403574e-03  3.20246952e-02\n",
      "  -1.25814898e-01  7.75457019e-01 -6.38703781e-01 -6.21930300e-01\n",
      "  -6.15622582e-01 -1.63396342e-02 -1.03066647e-01 -2.69634673e-01]\n",
      " [ 1.06213144e+00 -1.11477221e-01 -1.80896883e-01 -3.01610770e-02\n",
      "   6.36612300e-02 -2.31131457e-02  2.34941308e-02  1.81205690e-03\n",
      "  -2.48838512e+00 -3.58069059e-03  1.19719417e-04  4.36535634e-01\n",
      "   4.05027170e-04  9.55365398e-03 -2.79878187e-03 -2.35306286e-02\n",
      "   1.25769072e-01  4.03059477e-01 -5.40799993e-01  4.96166175e-01\n",
      "   4.38771397e-01 -2.50676193e-02 -9.30945923e-03  2.19507022e-01]\n",
      " [-1.23818403e+00  1.84863811e-02 -1.32052821e-01 -6.29134416e-02\n",
      "  -1.86668578e-02  1.54378060e-01  4.79910680e-02 -1.58161758e-03\n",
      "   9.94185943e-01  1.21263357e-02 -9.94142848e-04  4.41060575e-01\n",
      "  -2.76657784e-04  3.84593960e-03 -1.64525399e-03 -8.49406660e-03\n",
      "   4.58265418e-05 -1.17851650e+00  1.17950377e+00  1.25764125e-01\n",
      "   1.76851185e-01  4.14072535e-02  1.12376106e-01  5.01276510e-02]] \n",
      "\n",
      "Probabilities:\n",
      " [[9.83176166e-01 2.35530515e-07 1.68235986e-02]\n",
      " [9.52504094e-01 4.19785972e-02 5.51730927e-03]\n",
      " [8.31015363e-01 4.51293453e-02 1.23855292e-01]\n",
      " ...\n",
      " [2.92940478e-01 2.95480208e-02 6.77511501e-01]\n",
      " [3.10385724e-01 3.93812842e-01 2.95801435e-01]\n",
      " [2.45406114e-01 3.49099569e-02 7.19683929e-01]]\n",
      "Probabilities:\n",
      " [[7.29248062e-01 2.43785876e-01 2.69660620e-02]\n",
      " [3.73967772e-01 3.86347076e-02 5.87397520e-01]\n",
      " [6.01127691e-01 1.59085233e-02 3.82963785e-01]\n",
      " ...\n",
      " [8.58099753e-01 8.62997362e-02 5.56005110e-02]\n",
      " [8.15041174e-01 3.55735351e-05 1.84923252e-01]\n",
      " [1.07851837e-01 1.45306885e-01 7.46841278e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Logistic Regression Model with CV:\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Model_CV=LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_CV_strat = Model_CV.fit(trainx1_strat,trainy1_strat)\n",
    "print(Model_CV.fit(trainx1_strat,trainy1_strat))\n",
    "#print(Model_Strat.intercept_)\n",
    "#print(Model_Strat.coef_)\n",
    "pred_train = Model_CV.predict(trainx1_strat)\n",
    "print(pred_train)\n",
    "pred_test= Model_CV.predict(testx1_strat)\n",
    "print(pred_test)\n",
    "pred_val = Model_CV.predict(val_x)\n",
    "Val_pred = Model_CV.predict(val_x)\n",
    "print(\"Intercepts:\\n\",Model_CV_strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_CV_strat.coef_,\"\\n\")\n",
    "print(\"Probabilities:\\n\",Model_CV_strat.predict_proba(trainx1_strat))\n",
    "print(\"Probabilities:\\n\",Model_CV_strat.predict_proba(testx1_strat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the Classification Report of the Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     79856\n",
      "           1       0.59      0.48      0.53     16140\n",
      "           2       0.72      0.67      0.69     26986\n",
      "\n",
      "    accuracy                           0.80    122982\n",
      "   macro avg       0.72      0.68      0.70    122982\n",
      "weighted avg       0.79      0.80      0.79    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71      3336\n",
      "           1       0.73      0.46      0.57      2727\n",
      "           2       0.83      0.69      0.75      4452\n",
      "\n",
      "    accuracy                           0.70     10515\n",
      "   macro avg       0.72      0.68      0.68     10515\n",
      "weighted avg       0.73      0.70      0.69     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71      3318\n",
      "           1       0.72      0.47      0.57      2653\n",
      "           2       0.83      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.70     10515\n",
      "   macro avg       0.71      0.68      0.68     10515\n",
      "weighted avg       0.73      0.70      0.69     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     79856\n",
      "           1       0.59      0.48      0.53     16140\n",
      "           2       0.72      0.67      0.69     26986\n",
      "\n",
      "    accuracy                           0.80    122982\n",
      "   macro avg       0.72      0.68      0.70    122982\n",
      "weighted avg       0.79      0.80      0.79    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71      3336\n",
      "           1       0.73      0.46      0.57      2727\n",
      "           2       0.83      0.69      0.75      4452\n",
      "\n",
      "    accuracy                           0.70     10515\n",
      "   macro avg       0.72      0.68      0.68     10515\n",
      "weighted avg       0.73      0.70      0.69     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71      3318\n",
      "           1       0.72      0.47      0.57      2653\n",
      "           2       0.83      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.70     10515\n",
      "   macro avg       0.71      0.68      0.68     10515\n",
      "weighted avg       0.73      0.70      0.69     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trainy1_strat,predictions))\n",
    "print(classification_report(testy1_strat,predictions1))\n",
    "print(classification_report(val_y,predictions_val))\n",
    "print(classification_report(trainy1_strat,pred_train))\n",
    "print(classification_report(testy1_strat,pred_test))\n",
    "#print(classification_report(trainy1_strat,pred_train))\n",
    "print(classification_report(val_y,pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering extra tree classifer - feATURE elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking:\n",
      "1. feature 6 (0.112609)\n",
      "2. feature 17 (0.088833)\n",
      "3. feature 1 (0.076982)\n",
      "4. feature 16 (0.072746)\n",
      "5. feature 18 (0.066125)\n",
      "6. feature 19 (0.064908)\n",
      "7. feature 8 (0.054844)\n",
      "8. feature 22 (0.053782)\n",
      "9. feature 20 (0.042169)\n",
      "10. feature 0 (0.040760)\n",
      "11. feature 7 (0.039975)\n",
      "12. feature 12 (0.038907)\n",
      "13. feature 23 (0.036435)\n",
      "14. feature 14 (0.030889)\n",
      "15. feature 11 (0.026631)\n",
      "16. feature 21 (0.023568)\n",
      "17. feature 13 (0.022108)\n",
      "18. feature 10 (0.019040)\n",
      "19. feature 15 (0.018189)\n",
      "20. feature 3 (0.016625)\n",
      "21. feature 4 (0.016170)\n",
      "22. feature 5 (0.015634)\n",
      "23. feature 2 (0.014644)\n",
      "24. feature 9 (0.007429)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "forest.fit(trainx1_strat,trainy1_strat)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature Ranking:\")\n",
    "for f in range(trainx1_strat.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(trainx1_strat.shape[1]),importances[indices],color=\"r\",yerr=std[indices],align=\"center\")\n",
    "plt.xticks(range(trainx1_strat.shape[1]),indices)\n",
    "plt.xlim([-1,trainx1_strat.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature to be removed: 21\n",
      "Feature to be removed: 13\n",
      "Feature to be removed: 10\n",
      "Feature to be removed: 15\n",
      "Feature to be removed: 3\n",
      "Feature to be removed: 4\n",
      "Feature to be removed: 5\n",
      "Feature to be removed: 2\n",
      "Feature to be removed: 9\n",
      "[21, 13, 10, 15, 3, 4, 5, 2, 9]\n",
      "Features to be eliminated: [21, 13, 10, 15, 3, 4, 5, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "data_15feat= []\n",
    "for f in range(trainx1_strat.shape[1]):\n",
    "   # print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    if(importances[indices[f]] < 0.026):\n",
    "        print(\"Feature to be removed:\",indices[f])\n",
    "        data_15feat.append(indices[f])\n",
    "        count = count + 1\n",
    "    \n",
    "print(data_15feat)\n",
    "print(\"Features to be eliminated:\",data_15feat)\n",
    "Feature_elimination = pd.DataFrame(data_15feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature to be removed: 23\n",
      "Feature to be removed: 14\n",
      "Feature to be removed: 11\n",
      "Feature to be removed: 21\n",
      "Feature to be removed: 13\n",
      "Feature to be removed: 10\n",
      "Feature to be removed: 15\n",
      "Feature to be removed: 3\n",
      "Feature to be removed: 4\n",
      "Feature to be removed: 5\n",
      "Feature to be removed: 2\n",
      "Feature to be removed: 9\n",
      "[23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n",
      "Features to be eliminated: [23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "data_12feat= []\n",
    "for f in range(trainx1_strat.shape[1]):\n",
    "   # print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    if(importances[indices[f]] < 0.038):\n",
    "        print(\"Feature to be removed:\",indices[f])\n",
    "        data_12feat.append(indices[f])\n",
    "        count = count + 1\n",
    "    \n",
    "print(data_12feat)\n",
    "print(\"Features to be eliminated:\",data_12feat)\n",
    "Feature_elimination = pd.DataFrame(data_12feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature to be removed: 7\n",
      "Feature to be removed: 12\n",
      "Feature to be removed: 23\n",
      "Feature to be removed: 14\n",
      "Feature to be removed: 11\n",
      "Feature to be removed: 21\n",
      "Feature to be removed: 13\n",
      "Feature to be removed: 10\n",
      "Feature to be removed: 15\n",
      "Feature to be removed: 3\n",
      "Feature to be removed: 4\n",
      "Feature to be removed: 5\n",
      "Feature to be removed: 2\n",
      "Feature to be removed: 9\n",
      "[7, 12, 23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n",
      "Features to be eliminated: [7, 12, 23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "data_10feat= []\n",
    "for f in range(trainx1_strat.shape[1]):\n",
    "   # print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    if(importances[indices[f]] < 0.04):\n",
    "        print(\"Feature to be removed:\",indices[f])\n",
    "        data_10feat.append(indices[f])\n",
    "        count = count + 1\n",
    "    \n",
    "print(data_10feat)\n",
    "print(\"Features to be eliminated:\",data_10feat)\n",
    "Feature_elimination = pd.DataFrame(data_10feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature to be removed: 18\n",
      "Feature to be removed: 19\n",
      "Feature to be removed: 8\n",
      "Feature to be removed: 22\n",
      "Feature to be removed: 20\n",
      "Feature to be removed: 0\n",
      "Feature to be removed: 7\n",
      "Feature to be removed: 12\n",
      "Feature to be removed: 23\n",
      "Feature to be removed: 14\n",
      "Feature to be removed: 11\n",
      "Feature to be removed: 21\n",
      "Feature to be removed: 13\n",
      "Feature to be removed: 10\n",
      "Feature to be removed: 15\n",
      "Feature to be removed: 3\n",
      "Feature to be removed: 4\n",
      "Feature to be removed: 5\n",
      "Feature to be removed: 2\n",
      "Feature to be removed: 9\n",
      "[18, 19, 8, 22, 20, 0, 7, 12, 23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n",
      "Features to be eliminated: [18, 19, 8, 22, 20, 0, 7, 12, 23, 14, 11, 21, 13, 10, 15, 3, 4, 5, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "data_5feat= []\n",
    "for f in range(trainx1_strat.shape[1]):\n",
    "   # print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    if(importances[indices[f]] < 0.067):\n",
    "        print(\"Feature to be removed:\",indices[f])\n",
    "        data_5feat.append(indices[f])\n",
    "        count = count + 1\n",
    "    \n",
    "print(data_5feat)\n",
    "print(\"Features to be eliminated:\",data_5feat)\n",
    "Feature_elimination = pd.DataFrame(data_5feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Continuous_years_of_membership', 'prim_top', 'visa_code', 'mpa_code', 'MEM_CODE', 'I_CLASS', 'I_SEX', 'LTL+Other Plan', 'md_do']\n"
     ]
    }
   ],
   "source": [
    "#Eliminating features with least importance\n",
    "Elim_cols_15feat = []\n",
    "for i in data_15feat:\n",
    "    #print(trainx1_strat.columns[i])\n",
    "    Elim_cols_15feat.append(trainx1_strat.columns[i])\n",
    "    \n",
    "print(Elim_cols_15feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMP_D', 'prim_pe', 'Current Member status', 'Continuous_years_of_membership', 'prim_top', 'visa_code', 'mpa_code', 'MEM_CODE', 'I_CLASS', 'I_SEX', 'LTL+Other Plan', 'md_do']\n"
     ]
    }
   ],
   "source": [
    "#Eliminating features with least importance\n",
    "Elim_cols_12feat = []\n",
    "for i in data_12feat:\n",
    "    #print(trainx1_strat.columns[i])\n",
    "    Elim_cols_12feat.append(trainx1_strat.columns[i])\n",
    "    \n",
    "print(Elim_cols_12feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISSU_STATE', 'prim_spec', 'CMP_D', 'prim_pe', 'Current Member status', 'Continuous_years_of_membership', 'prim_top', 'visa_code', 'mpa_code', 'MEM_CODE', 'I_CLASS', 'I_SEX', 'LTL+Other Plan', 'md_do']\n"
     ]
    }
   ],
   "source": [
    "#Eliminating features with least importance\n",
    "Elim_cols_10feat = []\n",
    "for i in data_10feat:\n",
    "    #print(trainx1_strat.columns[i])\n",
    "    Elim_cols_10feat.append(trainx1_strat.columns[i])\n",
    "    \n",
    "print(Elim_cols_10feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_E_15fea =trainx1_strat.drop(columns = Elim_cols_15feat,axis=1)\n",
    "F_E_1_15fea = testx1_strat.drop(columns = Elim_cols_15feat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_E_12fea =trainx1_strat.drop(columns = Elim_cols_12feat,axis=1)\n",
    "F_E_1_12fea = testx1_strat.drop(columns = Elim_cols_12feat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_E_10fea =trainx1_strat.drop(columns = Elim_cols_10feat,axis=1)\n",
    "F_E_1_10fea = testx1_strat.drop(columns = Elim_cols_10feat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122982, 12)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_E_12fea.head()\n",
    "F_E_1_10fea.head()\n",
    "F_E_12fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10515, 15)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_15fea =val_x.drop(columns = Elim_cols_15feat,axis=1)\n",
    "VAL_15fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10515, 12)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_12fea =val_x.drop(columns = Elim_cols_12feat,axis=1)\n",
    "VAL_12fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10515, 10)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_10fea =val_x.drop(columns = Elim_cols_10feat,axis=1)\n",
    "VAL_10fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features Identified: Index(['.of Mails', 'Term', 'MODE', 'RISK_CLASS', 'ANNZD_PREM', 'I_CURR_AGE',\n",
      "       'I_AGE_ISSU', 'yrs_pract', 'Total_years_of_membership', 'EFF_D'],\n",
      "      dtype='object')\n",
      "Top 12 Features Identified: Index(['.of Mails', 'Term', 'MODE', 'ISSU_STATE', 'RISK_CLASS', 'prim_spec',\n",
      "       'ANNZD_PREM', 'I_CURR_AGE', 'I_AGE_ISSU', 'yrs_pract',\n",
      "       'Total_years_of_membership', 'EFF_D'],\n",
      "      dtype='object')\n",
      "Top 15 Features Identified: Index(['.of Mails', 'Term', 'MODE', 'ISSU_STATE', 'RISK_CLASS',\n",
      "       'Current Member status', 'prim_spec', 'prim_pe', 'ANNZD_PREM',\n",
      "       'I_CURR_AGE', 'I_AGE_ISSU', 'yrs_pract', 'Total_years_of_membership',\n",
      "       'EFF_D', 'CMP_D'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 Features Identified:\",F_E_10fea.columns)\n",
    "print(\"Top 12 Features Identified:\",F_E_12fea.columns)\n",
    "print(\"Top 15 Features Identified:\",F_E_15fea.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Logistic regression with 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35417782  0.89406235 -0.53988454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[-0.35417782  0.89406235 -0.53988454]\n",
      "[[ 0.19650836  0.11768724 -0.07450235  1.55701486 -0.12304729  0.68013807\n",
      "  -0.61386304  0.02149233  0.12881637 -0.22267498]\n",
      " [ 1.01102525 -0.12865749  0.02599307 -2.52718978  0.11478359  0.46590793\n",
      "  -0.56360136 -0.09298033  0.03085939  0.05734229]\n",
      " [-1.20753361  0.01097025  0.04850928  0.97017492  0.0082637  -1.146046\n",
      "   1.17746441  0.071488   -0.15967576  0.16533269]]\n",
      "[0 0 0 ... 2 0 2]\n",
      "[0 2 0 ... 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_strat1 = LogisticRegression(random_state=0,C=1.0,max_iter=50,penalty='l2')\n",
    "Model_Strat=logmodel_strat.fit(F_E_10fea,trainy1_strat)\n",
    "#print(logmodel_strat.fit(trainx1_strat,trainy1_strat))\n",
    "print(logmodel_strat.intercept_)\n",
    "#y = mx \n",
    "print(logmodel_strat1.fit(F_E_10fea,trainy1_strat))\n",
    "print(Model_Strat.intercept_)\n",
    "print(Model_Strat.coef_)\n",
    "pred_train_10fea = logmodel_strat1.predict(F_E_10fea)\n",
    "print(pred_train_10fea)\n",
    "pred_test_10fea = logmodel_strat1.predict(F_E_1_10fea)\n",
    "print(pred_test_10fea)\n",
    "Val_pred_10fea = logmodel_strat1.predict(VAL_10fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87     79856\n",
      "           1       0.55      0.33      0.42     16140\n",
      "           2       0.72      0.67      0.69     26986\n",
      "\n",
      "    accuracy                           0.78    122982\n",
      "   macro avg       0.70      0.64      0.66    122982\n",
      "weighted avg       0.77      0.78      0.77    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.90      0.68      3336\n",
      "           1       0.71      0.33      0.45      2727\n",
      "           2       0.83      0.69      0.75      4452\n",
      "\n",
      "    accuracy                           0.66     10515\n",
      "   macro avg       0.69      0.64      0.63     10515\n",
      "weighted avg       0.71      0.66      0.65     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.90      0.67      3318\n",
      "           1       0.70      0.33      0.45      2653\n",
      "           2       0.83      0.67      0.74      4544\n",
      "\n",
      "    accuracy                           0.66     10515\n",
      "   macro avg       0.69      0.64      0.62     10515\n",
      "weighted avg       0.71      0.66      0.65     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions3 = forest.predict(F_E,testy1_strat)from sklearn.metrics import cl\n",
    "print(classification_report(trainy1_strat,pred_train_10fea))\n",
    "print(classification_report(testy1_strat,pred_test_10fea))\n",
    "print(classification_report(val_y,Val_pred_10fea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with 10features with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[0 0 0 ... 2 0 2]\n",
      "[0 2 0 ... 0 0 2]\n",
      "Intercepts:\n",
      " [-0.35417782  0.89406235 -0.53988454] \n",
      "\n",
      "Coefficients\n",
      ": [[ 0.19650836  0.11768724 -0.07450235  1.55701486 -0.12304729  0.68013807\n",
      "  -0.61386304  0.02149233  0.12881637 -0.22267498]\n",
      " [ 1.01102525 -0.12865749  0.02599307 -2.52718978  0.11478359  0.46590793\n",
      "  -0.56360136 -0.09298033  0.03085939  0.05734229]\n",
      " [-1.20753361  0.01097025  0.04850928  0.97017492  0.0082637  -1.146046\n",
      "   1.17746441  0.071488   -0.15967576  0.16533269]] \n",
      "\n",
      "Probabilities:\n",
      " [[8.19837507e-01 1.59192629e-01 2.09698644e-02]\n",
      " [3.23119074e-01 3.83930826e-02 6.38487844e-01]\n",
      " [7.95949234e-01 7.92255806e-03 1.96128208e-01]\n",
      " ...\n",
      " [6.65307478e-01 1.83080351e-01 1.51612171e-01]\n",
      " [8.46747141e-01 2.15974797e-05 1.53231261e-01]\n",
      " [1.09500175e-01 1.55129964e-01 7.35369861e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model with CV:\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "Model_CV=LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_CV_strat = Model_CV.fit(F_E_10fea,trainy1_strat)\n",
    "print(Model_CV.fit(F_E_10fea,trainy1_strat))\n",
    "#print(Model_Strat.intercept_)\n",
    "#print(Model_Strat.coef_)\n",
    "pred_train_10feacv = Model_CV.predict(F_E_10fea)\n",
    "print(pred_train_10feacv)\n",
    "pred_test_10feacv = Model_CV.predict(F_E_1_10fea)\n",
    "print(pred_test_10feacv)\n",
    "Val_pred_10feacv = Model_CV.predict(VAL_10fea)\n",
    "print(\"Intercepts:\\n\",Model_CV_strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_CV_strat.coef_,\"\\n\")\n",
    "print(\"Probabilities:\\n\",Model_CV_strat.predict_proba(F_E_1_10fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86     79856\n",
      "           1       0.54      0.42      0.47     16140\n",
      "           2       0.72      0.68      0.70     26986\n",
      "\n",
      "    accuracy                           0.78    122982\n",
      "   macro avg       0.70      0.66      0.68    122982\n",
      "weighted avg       0.77      0.78      0.78    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3336\n",
      "           1       0.71      0.41      0.52      2727\n",
      "           2       0.83      0.69      0.76      4452\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.65     10515\n",
      "weighted avg       0.72      0.68      0.67     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3318\n",
      "           1       0.71      0.42      0.53      2653\n",
      "           2       0.84      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.66     10515\n",
      "weighted avg       0.72      0.68      0.67     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trainy1_strat,pred_train_10feacv))\n",
    "print(classification_report(testy1_strat,pred_test_10feacv))\n",
    "print(classification_report(val_y,Val_pred_10feacv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[0 0 0 ... 2 0 2]\n",
      "[0 2 0 ... 0 0 2]\n",
      "Intercepts:\n",
      " [-0.31007558  0.79133505 -0.48125946] \n",
      "\n",
      "Coefficients\n",
      ": [[ 1.95143273e-01  1.17527322e-01 -7.45161361e-02 -6.00006158e-04\n",
      "   1.55783020e+00 -2.64003057e-04 -1.23283426e-01  6.80188250e-01\n",
      "  -6.13746742e-01  1.71807944e-02  1.30353065e-01 -2.20699638e-01]\n",
      " [ 1.01471951e+00 -1.28304532e-01  2.60834121e-02  1.89394464e-03\n",
      "  -2.52925306e+00  4.92002097e-04  1.15603620e-01  4.65977809e-01\n",
      "  -5.63908837e-01 -8.46970467e-02  2.67127331e-02  5.33554390e-02]\n",
      " [-1.20986279e+00  1.07772100e-02  4.84327240e-02 -1.29393839e-03\n",
      "   9.71422864e-01 -2.27999473e-04  7.67980610e-03 -1.14616606e+00\n",
      "   1.17765558e+00  6.75162523e-02 -1.57065798e-01  1.67344199e-01]] \n",
      "\n",
      "Probabilities:\n",
      " [[8.16899400e-01 1.62356046e-01 2.07445532e-02]\n",
      " [3.25329204e-01 4.02245673e-02 6.34446229e-01]\n",
      " [7.95777910e-01 7.73771043e-03 1.96484380e-01]\n",
      " ...\n",
      " [6.67275464e-01 1.82318350e-01 1.50406186e-01]\n",
      " [8.48827694e-01 2.23477153e-05 1.51149958e-01]\n",
      " [1.09597269e-01 1.53031458e-01 7.37371274e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_strat1 = LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_Strat=logmodel_strat1.fit(F_E_12fea,trainy1_strat)\n",
    "#print(logmodel_strat.fit(trainx1_strat,trainy1_strat))\n",
    "#print(logmodel_strat1.intercept_)\n",
    "#y = mx \n",
    "print(logmodel_strat1.fit(F_E_12fea,trainy1_strat))\n",
    "#print(Model_Strat.intercept_)\n",
    "#print(Model_Strat.coef_)\n",
    "pred_train_12fea = logmodel_strat1.predict(F_E_12fea)\n",
    "print(pred_train_12fea)\n",
    "pred_test_12fea = logmodel_strat1.predict(F_E_1_12fea)\n",
    "print(pred_test_12fea)\n",
    "Val_pred_12fea = logmodel_strat1.predict(VAL_12fea)\n",
    "print(\"Intercepts:\\n\",Model_Strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_Strat.coef_,\"\\n\")\n",
    "print(\"Probabilities:\\n\",Model_Strat.predict_proba(F_E_1_12fea))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[0 0 0 ... 2 0 2]\n",
      "[0 2 0 ... 0 0 2]\n",
      "(10515,)\n",
      "Intercepts:\n",
      " [-0.31007558  0.79133505 -0.48125946] \n",
      "\n",
      "Coefficients\n",
      ": [[ 1.95143273e-01  1.17527322e-01 -7.45161361e-02 -6.00006158e-04\n",
      "   1.55783020e+00 -2.64003057e-04 -1.23283426e-01  6.80188250e-01\n",
      "  -6.13746742e-01  1.71807944e-02  1.30353065e-01 -2.20699638e-01]\n",
      " [ 1.01471951e+00 -1.28304532e-01  2.60834121e-02  1.89394464e-03\n",
      "  -2.52925306e+00  4.92002097e-04  1.15603620e-01  4.65977809e-01\n",
      "  -5.63908837e-01 -8.46970467e-02  2.67127331e-02  5.33554390e-02]\n",
      " [-1.20986279e+00  1.07772100e-02  4.84327240e-02 -1.29393839e-03\n",
      "   9.71422864e-01 -2.27999473e-04  7.67980610e-03 -1.14616606e+00\n",
      "   1.17765558e+00  6.75162523e-02 -1.57065798e-01  1.67344199e-01]] \n",
      "\n",
      "Probabilities:\n",
      " [[8.16899400e-01 1.62356046e-01 2.07445532e-02]\n",
      " [3.25329204e-01 4.02245673e-02 6.34446229e-01]\n",
      " [7.95777910e-01 7.73771043e-03 1.96484380e-01]\n",
      " ...\n",
      " [6.67275464e-01 1.82318350e-01 1.50406186e-01]\n",
      " [8.48827694e-01 2.23477153e-05 1.51149958e-01]\n",
      " [1.09597269e-01 1.53031458e-01 7.37371274e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model with CV:\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "Model_CV=LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_CV_strat = Model_CV.fit(F_E_12fea,trainy1_strat)\n",
    "print(Model_CV.fit(F_E_12fea,trainy1_strat))\n",
    "#print(Model_Strat.intercept_)\n",
    "#print(Model_Strat.coef_)\n",
    "pred_train_12feacv = Model_CV_strat.predict(F_E_12fea)\n",
    "print(pred_train_12fea)\n",
    "pred_test_12feacv = Model_CV_strat.predict(F_E_1_12fea)\n",
    "print(pred_test_12fea)\n",
    "\n",
    "Val_pred_12feacv= Model_CV_strat.predict(VAL_12fea)\n",
    "print(Val_pred_12feacv.shape)\n",
    "#data=[]\n",
    "#Val_pred_12feacv=pd.DataFrame(data)\n",
    "#data.to_csv(\"ValidationPredictions.csv\")\n",
    "print(\"Intercepts:\\n\",Model_CV_strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_CV_strat.coef_,\"\\n\")\n",
    "print(\"Probabilities:\\n\",Model_CV_strat.predict_proba(F_E_1_12fea))\n",
    "Val_prob_12fea = Model_CV_strat.predict_proba(VAL_12fea)\n",
    "test_prob_12fea=Model_CV_strat.predict_proba(F_E_1_12fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95143273e-01,  1.17527322e-01, -7.45161361e-02,\n",
       "        -6.00006158e-04,  1.55783020e+00, -2.64003057e-04,\n",
       "        -1.23283426e-01,  6.80188250e-01, -6.13746742e-01,\n",
       "         1.71807944e-02,  1.30353065e-01, -2.20699638e-01],\n",
       "       [ 1.01471951e+00, -1.28304532e-01,  2.60834121e-02,\n",
       "         1.89394464e-03, -2.52925306e+00,  4.92002097e-04,\n",
       "         1.15603620e-01,  4.65977809e-01, -5.63908837e-01,\n",
       "        -8.46970467e-02,  2.67127331e-02,  5.33554390e-02],\n",
       "       [-1.20986279e+00,  1.07772100e-02,  4.84327240e-02,\n",
       "        -1.29393839e-03,  9.71422864e-01, -2.27999473e-04,\n",
       "         7.67980610e-03, -1.14616606e+00,  1.17765558e+00,\n",
       "         6.75162523e-02, -1.57065798e-01,  1.67344199e-01]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_CV_strat.intercept_\n",
    "Model_CV_strat.classes_\n",
    "Model_CV_strat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86     79856\n",
      "           1       0.54      0.42      0.47     16140\n",
      "           2       0.72      0.68      0.70     26986\n",
      "\n",
      "    accuracy                           0.78    122982\n",
      "   macro avg       0.70      0.66      0.68    122982\n",
      "weighted avg       0.77      0.78      0.78    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3336\n",
      "           1       0.71      0.40      0.51      2727\n",
      "           2       0.83      0.69      0.76      4452\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.65     10515\n",
      "weighted avg       0.72      0.68      0.67     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3318\n",
      "           1       0.71      0.42      0.53      2653\n",
      "           2       0.84      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.66     10515\n",
      "weighted avg       0.72      0.68      0.68     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions3 = forest.predict(F_E,testy1_strat)from sklearn.metrics import classification_report\n",
    "#predictions = forest.predict(F_E)\n",
    "#predictions1 = forest.predict(F_E_1)\n",
    "print(classification_report(trainy1_strat,pred_train_12fea))\n",
    "print(classification_report(testy1_strat,pred_test_12fea))\n",
    "print(classification_report(val_y,Val_pred_12fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86     79856\n",
      "           1       0.54      0.42      0.47     16140\n",
      "           2       0.72      0.68      0.70     26986\n",
      "\n",
      "    accuracy                           0.78    122982\n",
      "   macro avg       0.70      0.66      0.68    122982\n",
      "weighted avg       0.77      0.78      0.78    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3336\n",
      "           1       0.71      0.40      0.51      2727\n",
      "           2       0.83      0.69      0.76      4452\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.65     10515\n",
      "weighted avg       0.72      0.68      0.67     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69      3318\n",
      "           1       0.71      0.42      0.53      2653\n",
      "           2       0.84      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.68     10515\n",
      "   macro avg       0.70      0.66      0.66     10515\n",
      "weighted avg       0.72      0.68      0.68     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions3 = forest.predict(F_E,testy1_strat)from sklearn.metrics import classification_report\n",
    "#predictions = forest.predict(F_E)\n",
    "#predictions1 = forest.predict(F_E_1)\n",
    "print(classification_report(trainy1_strat,pred_train_12feacv))\n",
    "print(classification_report(testy1_strat,pred_test_12feacv))\n",
    "print(classification_report(val_y,Val_pred_12feacv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR with 15 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62823482  0.19460437 -0.8228392 ]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[ 0.62823482  0.19460437 -0.8228392 ]\n",
      "[[ 1.58215478e-01  1.02926833e-01 -7.33337159e-02 -2.07370642e-04\n",
      "   1.53576005e+00 -9.71909627e-01 -6.87251167e-05  1.64809311e-03\n",
      "  -1.30990138e-01  7.35587172e-01 -6.43806304e-01  1.76396436e-01\n",
      "  -8.05704596e-01 -1.53286777e-01 -2.69471797e-01]\n",
      " [ 1.03687709e+00 -1.17688111e-01  2.50354984e-02  1.58222154e-03\n",
      "  -2.54402449e+00  5.12785351e-01  3.53578633e-04 -7.86622917e-04\n",
      "   1.18723575e-01  4.29144255e-01 -5.33556042e-01 -1.18246186e-01\n",
      "   5.07696807e-01  2.27264358e-02  2.12703500e-01]\n",
      " [-1.19509256e+00  1.47612786e-02  4.82982175e-02 -1.37485086e-03\n",
      "   1.00826444e+00  4.59124276e-01 -2.84853804e-04 -8.61470232e-04\n",
      "   1.22665631e-02 -1.16473143e+00  1.17736235e+00 -5.81502500e-02\n",
      "   2.98007788e-01  1.30560341e-01  5.67682966e-02]]\n",
      "[0 0 0 ... 2 1 2]\n",
      "[0 2 0 ... 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_strat1 = LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_Strat=logmodel_strat.fit(F_E_15fea,trainy1_strat)\n",
    "#print(logmodel_strat.fit(trainx1_strat,trainy1_strat))\n",
    "print(logmodel_strat.intercept_)\n",
    "#y = mx \n",
    "print(logmodel_strat1.fit(F_E_15fea,trainy1_strat))\n",
    "print(Model_Strat.intercept_)\n",
    "print(Model_Strat.coef_)\n",
    "pred_train_15fea = logmodel_strat1.predict(F_E_15fea)\n",
    "print(pred_train_15fea)\n",
    "pred_test_15fea = logmodel_strat1.predict(F_E_1_15fea)\n",
    "print(pred_test_15fea)\n",
    "Val_pred_15fea = logmodel_strat1.predict(VAL_15fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     79856\n",
      "           1       0.58      0.46      0.51     16140\n",
      "           2       0.73      0.67      0.70     26986\n",
      "\n",
      "    accuracy                           0.79    122982\n",
      "   macro avg       0.72      0.68      0.70    122982\n",
      "weighted avg       0.79      0.79      0.79    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71      3336\n",
      "           1       0.73      0.45      0.56      2727\n",
      "           2       0.83      0.68      0.75      4452\n",
      "\n",
      "    accuracy                           0.69     10515\n",
      "   macro avg       0.71      0.68      0.67     10515\n",
      "weighted avg       0.72      0.69      0.69     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71      3318\n",
      "           1       0.72      0.46      0.56      2653\n",
      "           2       0.84      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.69     10515\n",
      "   macro avg       0.71      0.68      0.67     10515\n",
      "weighted avg       0.73      0.69      0.69     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions3 = forest.predict(F_E,testy1_strat)from sklearn.metrics import classification_report\n",
    "#predictions = forest.predict(F_E)\n",
    "#predictions1 = forest.predict(F_E_1)\n",
    "print(classification_report(trainy1_strat,pred_train_15fea))\n",
    "print(classification_report(testy1_strat,pred_test_15fea))\n",
    "print(classification_report(val_y,Val_pred_15fea))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[0 0 0 ... 2 1 2]\n",
      "[0 2 0 ... 0 0 2]\n",
      "Intercepts:\n",
      " [ 0.62823482  0.19460437 -0.8228392 ] \n",
      "\n",
      "Coefficients\n",
      ": [[ 1.58215478e-01  1.02926833e-01 -7.33337159e-02 -2.07370642e-04\n",
      "   1.53576005e+00 -9.71909627e-01 -6.87251167e-05  1.64809311e-03\n",
      "  -1.30990138e-01  7.35587172e-01 -6.43806304e-01  1.76396436e-01\n",
      "  -8.05704596e-01 -1.53286777e-01 -2.69471797e-01]\n",
      " [ 1.03687709e+00 -1.17688111e-01  2.50354984e-02  1.58222154e-03\n",
      "  -2.54402449e+00  5.12785351e-01  3.53578633e-04 -7.86622917e-04\n",
      "   1.18723575e-01  4.29144255e-01 -5.33556042e-01 -1.18246186e-01\n",
      "   5.07696807e-01  2.27264358e-02  2.12703500e-01]\n",
      " [-1.19509256e+00  1.47612786e-02  4.82982175e-02 -1.37485086e-03\n",
      "   1.00826444e+00  4.59124276e-01 -2.84853804e-04 -8.61470232e-04\n",
      "   1.22665631e-02 -1.16473143e+00  1.17736235e+00 -5.81502500e-02\n",
      "   2.98007788e-01  1.30560341e-01  5.67682966e-02]] \n",
      "\n",
      "Probabilities:\n",
      " [[7.45890884e-01 2.26532956e-01 2.75761595e-02]\n",
      " [2.67242970e-01 4.77747497e-02 6.84982280e-01]\n",
      " [6.28045306e-01 1.55796011e-02 3.56375093e-01]\n",
      " ...\n",
      " [8.91541612e-01 5.76550061e-02 5.08033817e-02]\n",
      " [9.29591100e-01 9.36076571e-06 7.03995390e-02]\n",
      " [1.21602496e-01 1.47749579e-01 7.30647925e-01]]\n",
      "Probabilities of validation set:\n",
      " [[0.59984887 0.31720753 0.0829436 ]\n",
      " [0.41889441 0.35559509 0.22551051]\n",
      " [0.91128952 0.03548347 0.05322701]\n",
      " ...\n",
      " [0.91964744 0.00698944 0.07336313]\n",
      " [0.35457869 0.58628967 0.05913164]\n",
      " [0.07794476 0.20278365 0.71927159]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model with CV:\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "Model_CV=LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "Model_CV_strat = Model_CV.fit(F_E_15fea,trainy1_strat)\n",
    "print(Model_CV.fit(F_E_15fea,trainy1_strat))\n",
    "#print(Model_Strat.intercept_)\n",
    "#print(Model_Strat.coef_)\n",
    "pred_train_15feacv = Model_CV.predict(F_E_15fea)\n",
    "print(pred_train_15fea)\n",
    "pred_test_15feacv = Model_CV.predict(F_E_1_15fea)\n",
    "print(pred_test_15fea)\n",
    "Val_pred_15feacv = Model_CV.predict(VAL_15fea)\n",
    "print(\"Intercepts:\\n\",Model_CV_strat.intercept_,\"\\n\")\n",
    "print(\"Coefficients\\n:\",Model_CV_strat.coef_,\"\\n\")\n",
    "intercepts_15fea = Model_CV_strat.intercept_\n",
    "Coefficients_15fea = Model_CV_strat.coef_\n",
    "print(\"Probabilities:\\n\",Model_CV_strat.predict_proba(F_E_1_15fea))\n",
    "print(\"Probabilities of validation set:\\n\",Model_CV_strat.predict_proba(VAL_15fea))\n",
    "Val_prob_15fea = Model_CV_strat.predict_proba(VAL_15fea)\n",
    "prob_val_15=Model_CV_strat.predict_proba(VAL_15fea)\n",
    "test_prob_15fea=Model_CV_strat.predict_proba(F_E_1_15fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model with CV:\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "Model_CV=LogisticRegression(penalty=\"l2\",tol=0.0001,C=1.0,fit_intercept=True,solver=\"newton-cg\",max_iter=100,multi_class=\"multinomial\")\n",
    "F_E_15fea1= F_E_15fea.drop(columns=[\"RISK_CLASS\",\"prim_spec\"])\n",
    "Model_CV_strat = Model_CV.fit(F_E_15fea1,trainy1_strat)\n",
    "print(Model_CV.fit(F_E_15fea1,trainy1_strat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86     79856\n",
      "           1       0.56      0.37      0.45     16140\n",
      "           2       0.70      0.64      0.67     26986\n",
      "\n",
      "    accuracy                           0.77    122982\n",
      "   macro avg       0.69      0.64      0.66    122982\n",
      "weighted avg       0.76      0.77      0.76    122982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#F_E_1_15fea1=F_E_15fea1.drop(columns=[\"RISK_CLASS\",\"prim_spec\"])\n",
    "print(classification_report(trainy1_strat,Model_CV_strat.predict(F_E_15fea1)))\n",
    "#print(classification_report(testy1_strat,Model_CV_strat.predict(F_E_15fea1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intercepts_15 = pd.DataFrame(intercepts_15fea)\n",
    "df_Coefficients_15 = pd.DataFrame(Coefficients_15fea)\n",
    "df_intercepts_15.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\intercepts_15.csv\")\n",
    "df_Coefficients_15.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\Coefficients_15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_actux = pd.DataFrame(VAL_15fea)\n",
    "df_val_actux.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\Validation15actux.csv\")\n",
    "df_val_pred = pd.DataFrame(Val_pred_15feacv)\n",
    "df_val_actu = pd.DataFrame(val_y)\n",
    "df_val_prob = pd.DataFrame(prob_val_15)\n",
    "df_val_pred.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\valPred15.csv\")\n",
    "df_val_actu.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\valactu15.csv\")\n",
    "df_val_prob.to_csv(r\"\\\\iafs1\\data\\sa\\consultants\\Customers File\\valprob15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     79856\n",
      "           1       0.58      0.46      0.51     16140\n",
      "           2       0.73      0.67      0.70     26986\n",
      "\n",
      "    accuracy                           0.79    122982\n",
      "   macro avg       0.72      0.68      0.70    122982\n",
      "weighted avg       0.79      0.79      0.79    122982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71      3336\n",
      "           1       0.73      0.45      0.56      2727\n",
      "           2       0.83      0.68      0.75      4452\n",
      "\n",
      "    accuracy                           0.69     10515\n",
      "   macro avg       0.71      0.68      0.67     10515\n",
      "weighted avg       0.72      0.69      0.69     10515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71      3318\n",
      "           1       0.72      0.46      0.56      2653\n",
      "           2       0.84      0.68      0.75      4544\n",
      "\n",
      "    accuracy                           0.69     10515\n",
      "   macro avg       0.71      0.68      0.67     10515\n",
      "weighted avg       0.73      0.69      0.69     10515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions3 = forest.predict(F_E,testy1_strat)from sklearn.metrics import classification_report\n",
    "#predictions = forest.predict(F_E)\n",
    "#predictions1 = forest.predict(F_E_1)\n",
    "print(classification_report(trainy1_strat,pred_train_15feacv))\n",
    "print(classification_report(testy1_strat,pred_test_15feacv))\n",
    "print(classification_report(val_y,Val_pred_15feacv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
